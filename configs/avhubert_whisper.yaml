# Configuration for AVHuBERT-Whisper Model

# Model configuration
llm_path: "checkpoints/Llama-3.2-1B"
whisper_model: "openai/whisper-medium"
avhubert_path: "checkpoints/large_vox_iter5.pt"
modality: "both"  # Options: "audio", "video", "both"
use_fp16: false
freeze_encoders: true
freeze_llm: false
fusion_scale: 0.5  # Weight for audio in fusion (0.5 = equal weight)
max_seq_len: 256

# LoRA configuration
use_lora: true
lora_r: 16
lora_alpha: 32
lora_dropout: 0.05

# Training configuration
learning_rate: 5e-5
weight_decay: 0.01
max_epochs: 10
batch_size: 4
grad_accum_steps: 4
max_grad_norm: 0.5
warmup_ratio: 0.1
log_interval: 10
save_every: 1
save_steps: null

# Data configuration
data_path: "data"
max_audio_length: 30  # seconds
max_video_length: 300  # frames

# Output configuration
output_dir: "outputs/avhubert_whisper" 